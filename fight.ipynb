{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31381707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import _game\n",
    "import _bot_b\n",
    "\n",
    "import importlib\n",
    "importlib.reload(_game)\n",
    "importlib.reload(_bot_b)\n",
    "\n",
    "from _game import Game, Game_Hokom, Game_Sun, Bot_Random\n",
    "from _bot_b import Bot, Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8df870",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5e7a3bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bots = [Bot(models=models) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ea552cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Game_Hokom(verbose=1)\n",
    "game.register(bots=bots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a54c8495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.hokum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "81547efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot 3 played ♦9 (♠K ♥9 ♥J ♥K ♣9 ♣J ♣K)\n",
      "Bot 0 played ♦10 (♠7 ♠J ♠A ♣7 ♣Q ♦Q ♦A)\n",
      "Bot 1 played ♦K (♠9 ♠Q ♥7 ♥Q ♥A ♣10 ♦7)\n",
      "Bot 2 played ♦J (♠8 ♠10 ♥8 ♥10 ♣8 ♣A ♦8)\n",
      "Round:1 score:16 Scores:[ 16 -16]\n"
     ]
    }
   ],
   "source": [
    "game.oneround()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "df4845dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hokum: ♠\n",
      "Bot 3 played ♦8 (♠7 ♠8 ♥8 ♥10 ♥A ♣Q ♦A)\n",
      "Bot 0 played ♦J (♠9 ♠A ♥Q ♥K ♣10 ♦Q ♦K)\n",
      "Bot 1 played ♦7 (♠10 ♠K ♥9 ♥J ♣8 ♣J ♦9)\n",
      "Bot 2 played ♦10 (♠J ♠Q ♥7 ♣7 ♣9 ♣K ♣A)\n",
      "Round:1 score:12 Scores:12\n",
      "Bot 2 played ♣9 (♠J ♠Q ♥7 ♣7 ♣K ♣A)\n",
      "Bot 3 played ♣Q (♠7 ♠8 ♥8 ♥10 ♥A ♦A)\n",
      "Bot 0 played ♣10 (♠9 ♠A ♥Q ♥K ♦Q ♦K)\n",
      "Bot 1 played ♣J (♠10 ♠K ♥9 ♥J ♣8 ♦9)\n",
      "Round:2 score:15 Scores:27\n",
      "Bot 0 played ♠9 (♠A ♥Q ♥K ♦Q ♦K)\n",
      "Bot 1 played ♠10 (♠K ♥9 ♥J ♣8 ♦9)\n",
      "Bot 2 played ♠Q (♠J ♥7 ♣7 ♣K ♣A)\n",
      "Bot 3 played ♠8 (♠7 ♥8 ♥10 ♥A ♦A)\n",
      "Round:3 score:27 Scores:54\n",
      "Bot 0 played ♦K (♠A ♥Q ♥K ♦Q)\n",
      "Bot 1 played ♦9 (♠K ♥9 ♥J ♣8)\n",
      "Bot 2 played ♠J (♥7 ♣7 ♣K ♣A)\n",
      "Bot 3 played ♦A (♠7 ♥8 ♥10 ♥A)\n",
      "Round:4 score:35 Scores:89\n",
      "Bot 2 played ♣7 (♥7 ♣K ♣A)\n",
      "Bot 3 played ♠7 (♥8 ♥10 ♥A)\n",
      "Bot 0 played ♠A (♥Q ♥K ♦Q)\n",
      "Bot 1 played ♣8 (♠K ♥9 ♥J)\n",
      "Round:5 score:11 Scores:100\n",
      "Bot 0 played ♥K (♥Q ♦Q)\n",
      "Bot 1 played ♥J (♠K ♥9)\n",
      "Bot 2 played ♥7 (♣K ♣A)\n",
      "Bot 3 played ♥A (♥8 ♥10)\n",
      "Round:6 score:17 Scores:83\n",
      "Bot 3 played ♥10 (♥8)\n",
      "Bot 0 played ♥Q (♦Q)\n",
      "Bot 1 played ♥9 (♠K)\n",
      "Bot 2 played ♣K (♣A)\n",
      "Round:7 score:17 Scores:66\n",
      "Bot 3 played ♥8 ()\n",
      "Bot 0 played ♦Q ()\n",
      "Bot 1 played ♠K ()\n",
      "Bot 2 played ♣A ()\n",
      "Round:8 score:18 Scores:48\n"
     ]
    }
   ],
   "source": [
    "game.whole_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9e47c657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 224])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.bots[0].data[0][\"x\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "6458e0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "aeb64783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Model(0)\n",
    "model2.load_state_dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "6b0c5d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0762,  0.0847,  0.0408, -0.0605, -0.0774])\n",
      "tensor([ 0.0762,  0.0847,  0.0408, -0.0605, -0.0774])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict()['lstm.weight_ih_l0'][0,0:5])\n",
    "print(model2.state_dict()['lstm.weight_ih_l0'][0,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "0194ec4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[300], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     19\u001b[0m loss_sum \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(losses)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m---> 20\u001b[0m \u001b[43mloss_sum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()    \n",
      "File \u001b[1;32mc:\\Users\\BNCD\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BNCD\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BNCD\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    824\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    825\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "log_probs = []\n",
    "rs = []\n",
    "for _ in range(100):\n",
    "    zs = torch.randn(1, 6, 224)\n",
    "    xs = torch.randn(1, 192)\n",
    "    logits = model2(zs, xs)\n",
    "    dist = torch.distributions.Categorical(logits=logits)\n",
    "    acts = dist.sample()\n",
    "    log_prob = dist.log_prob(acts)\n",
    "    log_probs.append(log_prob.detach())\n",
    "    r = torch.randn(1)[0] * 10\n",
    "    rs.append(r)\n",
    "\n",
    "losses = []\n",
    "for log_prob, r in zip(log_probs, rs):\n",
    "    losses.append(-log_prob * r)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss_sum = torch.stack(losses).sum()\n",
    "loss_sum.backward()\n",
    "optimizer.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "599befd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0405, -0.0289, -0.0490, -0.0460, -0.0867])\n",
      "tensor([ 0.0405, -0.0289, -0.0490, -0.0460, -0.0867])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict()['lstm.weight_ih_l0'][0,0:5])\n",
    "print(model2.state_dict()['lstm.weight_ih_l0'][0,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "38ed27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(models):\n",
    "    score = 0\n",
    "    bots = [Bot(models=models), Bot_Random(), Bot(models=models), Bot_Random()]\n",
    "    game1 = Game()\n",
    "    game1.register_bots(bots)\n",
    "    game1.whole_game()\n",
    "    scores1 = game1.scores\n",
    "    score = score + np.sum(game1.scores)\n",
    "    \n",
    "    \n",
    "    bots = [Bot_Random(), Bot(models=models), Bot_Random(), Bot(models=models)]\n",
    "    game2 = Game()\n",
    "    game2.register_bots(bots)\n",
    "    game2.whole_game()\n",
    "    scores2 = game2.scores\n",
    "    score = score - np.sum(game2.scores)\n",
    "    \n",
    "    return score, scores1, scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "adbe9ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(162)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, scores1, scores2 = eval(models)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "b420379c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(152)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(scores2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f7494a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
